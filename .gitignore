
def word_counter #(txt)
# 	Add in new alternative to failure

	if ARGV[0].nil?
		puts "Please enter a filename following the program name."
		puts "Exitting Program"
		exit(0)
	else
		txt = File.open(ARGV[0], "r+")
	end
#	figure out how tokenizer works
#	m = TactfulTokenizer::Model.new
#	p m.tokenize_text("Given an arbitrary text document written in English, write a program that will generate a concordance, i.e. an alphabetical list of all word occurrences, labeled with word frequencies. Bonus: label each word with the sentence numbers in which each occurrence appeared.")

	h = Hash.new(0); i = 0;	alph = "a".ord 
		# setting new values
		
	txt = txt.read.downcase.scan(/[\w']+/).sort.each {|elmt| h[elmt] +=1}
		# finding word without gramatical interruption and sorting vals
		# finding frequency for each word that appears and storing in hash

	val = (h.keys.max_by(&:length)).length + 10
		# setting indent length for table formatting

	printf "%-#{val + 1}s %s\n","Word List","Frequency & Locations"
		# title of printed table, 
	h.each do |k, v| 
		str = "" # resetting alpha value so as not to include previous
		((i / 26)+1).times {str += (alph + (i % 26)).chr}
			# dynamically increase list alphabetically and roll over at end of alpha
		printf("%s. %-#{val - str.length}s{%s:loc(1), loc(2), etc}\n", str,k,v) 
			# dynamically create output table
		i += 1
			# increment through alpha
	end
end
var = """Given an arbitrary text document written in English, write a program that will generate a
concordance, i.e. an alphabetical list of all word occurrences, labeled with word frequencies.
Bonus: label each word with the sentence numbers in which each occurrence appeared."""
word_counter
